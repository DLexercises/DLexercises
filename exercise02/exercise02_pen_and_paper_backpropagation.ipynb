{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pen & Paper: Backpropagation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perform a forward and backward pass to calculate the gradients for the weights $w_0, w_1, w_2, w_s$ in the following MLP. Each node represents one unit with a weight $w_i, i \\in \\{0, 1, 2\\}$ connecting it to the previous node. The connection from unit 0 to unit 2 is called a _skip connection_, which means unit 2 receives input from two sources and thus has an additional weight $w_s$. The weighted inputs are added before the nonlinearity is applied.\n",
    "\n",
    "**![There should be an image here. If you can't see it, you probably forgot to download the mlp.png!](mlp.png)**\n",
    "\n",
    "We assume that we want to solve a regression task. We use an L1-loss $L(\\hat{y}, y) = |y - \\hat{y}|$\n",
    "\n",
    "The nonlinearities for the first two units are rectified linear functions/units (ReLU): $g_0(z) = g_1(z) = \\begin{cases} 0, z<0\\\\ z, else \\end{cases}$.\n",
    "\n",
    "We do not use a nonlinearity for the second unit: $g_2(z_2) = z_2$.\n",
    "\n",
    "**Note:** We use the notation of the Deep Learning book here, i.e. $z = Wx+b$. If you attended the Machine Learning course, you might be used to the different notation used in the Bishop Book, where $z$ denotes the value after applying the activation function. Here, $z$ is the value before applying the activation function.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Complete the backpropagation algorithm**\n",
    "\n",
    "#### Forward Pass\n",
    "\\begin{align*}\n",
    "    z_0 &= w_0 + x \\\\\n",
    "    h_0 &= g_0(z_0) \\\\\n",
    "    z_1 &= w_1 + h_1 \\\\\n",
    "    h_1 &= g_1(z_1) \\\\\n",
    "    z_2 &= w_h h_1 + w_s h_0 \\\\\n",
    "    \\hat{y} &= z_2\n",
    "\\end{align*}\n",
    "#### Backward Pass\n",
    "\\begin{align*}\n",
    "\\frac{\\partial L}{\\partial \\hat{y}} &= \\begin{cases}1 & \\text{if } \\hat{y} \\geq y\\\\-1 & \\text{else} \\end{cases} \\\\\n",
    "\\frac{\\partial L}{\\partial z_2} &= \\frac{\\partial L}{\\partial \\hat{y}} \\cdot \\frac{\\partial \\hat{y}}{\\partial z_2} = \\frac{\\partial L}{\\partial \\hat{y}} \\cdot 1 \\\\\n",
    "\\frac{\\partial L}{\\partial w_2} &= \\frac{\\partial L}{\\partial z_2} \\cdot \\frac{\\partial z_2}{\\partial w_2} = \\frac{\\partial L}{\\partial z_2} \\cdot h_1 \\\\\n",
    "\\frac{\\partial L}{\\partial w_s} &= \\frac{\\partial L}{\\partial z_2} \\cdot \\frac{\\partial z_2}{\\partial w_s} = \\frac{\\partial L}{\\partial z_2} \\cdot h_0 \\\\\n",
    "\\frac{\\partial L}{\\partial h_1} &= \\frac{\\partial L}{\\partial z_2} \\cdot \\frac{\\partial z_2}{\\partial h_1} = \\frac{\\partial L}{\\partial z_2} \\cdot w_2 \\\\\n",
    "\\frac{\\partial L}{\\partial z_1} &= \\frac{\\partial L}{\\partial h_1} \\cdot \\frac{\\partial h_1}{\\partial z_1} = \\frac{\\partial L}{\\partial h_1} \\cdot \\begin{cases}1 & \\text{if } z_1 \\geq 0\\\\0 & \\text{else} \\end{cases}\\\\\n",
    "\\frac{\\partial L}{\\partial w_1} &= \\frac{\\partial L}{\\partial z_1} \\cdot \\frac{\\partial z_1}{\\partial w_1} = \\frac{\\partial L}{\\partial z_1} \\cdot h_0\\\\\n",
    "\\frac{\\partial L}{\\partial h_0} &= \\frac{\\partial L}{\\partial z_2} \\cdot \\frac{\\partial z_2}{\\partial h_0} + \\frac{\\partial L}{\\partial z_1} \\cdot \\frac{\\partial z_1}{\\partial h_0} = \\frac{\\partial L}{\\partial z_2} \\cdot w_0 + \\frac{\\partial L}{\\partial z_1} \\cdot w_1\\\\\n",
    "\\frac{\\partial L}{\\partial z_0} &= \\frac{\\partial L}{\\partial h_0} \\cdot \\frac{\\partial h_0}{\\partial z_0} = \\frac{\\partial L}{\\partial h_0} \\cdot \\begin{cases}1 & \\text{if } z_0 \\geq 0\\\\0 & \\text{else} \\end{cases}\\\\\n",
    "\\frac{\\partial L}{\\partial w_0} &= \\frac{\\partial L}{\\partial z_0} \\cdot \\frac{\\partial z_0}{\\partial w_0} = \\frac{\\partial L}{\\partial z_0} \\cdot x\\\\\n",
    "\\end{align*}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**What difference does the skip connection make when propagating back the error?** \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Calculate the gradients for the given datapoint and the given initial weights (calculating the gradients requires to calculate a forward pass first). Also calculate the weights and the loss after one gradient descent step.**\n",
    "\n",
    "$$(x_1, y_1) = (1, -3) \\\\\n",
    "w_0 = w_1 = w_2 = w_s = 0.5 \\\\\n",
    "Learning Rate = 1 \\\\  $$\n",
    "\n",
    "#### Calculation of the forward Pass\n",
    "\\begin{align*}\n",
    "    z_0 &= 0.5 \\\\\n",
    "    h_0 &= 0.5 \\\\\n",
    "    z_1 &= 0.25 \\\\\n",
    "    h_1 &= 0.25 \\\\\n",
    "    z_2 &= 0.375 \\\\\n",
    "    \\hat{y} &= 0.375 \\Rightarrow L = 3.375\n",
    "\\end{align*}\n",
    "#### Calculation of the backward Pass\n",
    "\\begin{align*}\n",
    "\\frac{\\partial L}{\\partial \\hat{y}} &= \\begin{cases}1 & \\text{if } \\hat{y} \\geq y\\\\-1 & \\text{else} \\end{cases} = 1 \\\\\n",
    "\\frac{\\partial L}{\\partial z_2} &= \\frac{\\partial L}{\\partial \\hat{y}} \\cdot \\frac{\\partial \\hat{y}}{\\partial z_2} = \\frac{\\partial L}{\\partial \\hat{y}} \\cdot 1 = 1\\\\\n",
    "\\frac{\\partial L}{\\partial w_2} &= \\frac{\\partial L}{\\partial z_2} \\cdot \\frac{\\partial z_2}{\\partial w_2} = \\frac{\\partial L}{\\partial z_2} \\cdot h_1 = 0.25\\\\\n",
    "\\frac{\\partial L}{\\partial w_s} &= \\frac{\\partial L}{\\partial z_2} \\cdot \\frac{\\partial z_2}{\\partial w_s} = \\frac{\\partial L}{\\partial z_2} \\cdot h_0 = 0.5\\\\\n",
    "\\frac{\\partial L}{\\partial h_1} &= \\frac{\\partial L}{\\partial z_2} \\cdot \\frac{\\partial z_2}{\\partial h_1} = \\frac{\\partial L}{\\partial z_2} \\cdot w_2 = 0.5\\\\\n",
    "\\frac{\\partial L}{\\partial z_1} &= \\frac{\\partial L}{\\partial h_1} \\cdot \\frac{\\partial h_1}{\\partial z_1} = \\frac{\\partial L}{\\partial h_1} \\cdot \\begin{cases}1 & \\text{if } z_1 \\geq 0\\\\0 & \\text{else} \\end{cases} = 0.5\\\\\n",
    "\\frac{\\partial L}{\\partial w_1} &= \\frac{\\partial L}{\\partial z_1} \\cdot \\frac{\\partial z_1}{\\partial w_1} = \\frac{\\partial L}{\\partial z_1} \\cdot h_0 = 0.25\\\\\n",
    "\\frac{\\partial L}{\\partial h_0} &= \\frac{\\partial L}{\\partial z_2} \\cdot \\frac{\\partial z_2}{\\partial h_0} + \\frac{\\partial L}{\\partial z_1} \\cdot \\frac{\\partial z_1}{\\partial h_0} = \\frac{\\partial L}{\\partial z_2} \\cdot w_0 + \\frac{\\partial L}{\\partial z_1} \\cdot w_1 = 0.75\\\\\n",
    "\\frac{\\partial L}{\\partial z_0} &= \\frac{\\partial L}{\\partial h_0} \\cdot \\frac{\\partial h_0}{\\partial z_0} = \\frac{\\partial L}{\\partial h_0} \\cdot \\begin{cases}1 & \\text{if } z_0 \\geq 0\\\\0 & \\text{else} \\end{cases} = 0.75\\\\\n",
    "\\frac{\\partial L}{\\partial w_0} &= \\frac{\\partial L}{\\partial z_0} \\cdot \\frac{\\partial z_0}{\\partial w_0} = \\frac{\\partial L}{\\partial z_0} \\cdot x = 0.75\\\\\n",
    "\\end{align*}\n",
    "##### Update weigths with Lerningrate 1\n",
    "\\begin{align*}\n",
    "    w_0 &= -0.25 \\\\\n",
    "    w_1 &= 0.25 \\\\\n",
    "    w_2 &= 0.25 \\\\\n",
    "    w_s &= 0\n",
    "\\end{align*}\n",
    "##### New Loss\n",
    "\\begin{align*}\n",
    "    z_0 &= -0.25 \\\\\n",
    "    h_0 &= 0 \\\\\n",
    "    z_1 &= 0 \\\\\n",
    "    h_1 &= 0 \\\\\n",
    "    z_2 &= 0 \\\\\n",
    "    \\hat{y} &= 0 \\Rightarrow L = 3\n",
    "\\end{align*}\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Your feedback on exercise 2.1: ** \n",
    "> This excercise was well defined and a meaningful preparation for the upcoming implementation of the mlp.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
